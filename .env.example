# Example environment variables for the AI microservices

# LLM Configuration
LLM_PROVIDER=openrouter  # or ollama, local
LLM_MODEL=gpt-3.5-turbo  # or your preferred model
LLM_API_KEY=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

# Flowise Configuration
FLOWISE_API_URL=http://localhost:3000
FLOWISE_API_KEY=your_flowise_api_key_here

# Database Configuration (if needed)
DATABASE_URL=sqlite:///./test.db

# Server Configuration
HOST=localhost
PORT=8000

# Document Processing
UPLOAD_FOLDER=./uploads
MAX_FILE_SIZE=10485760  # 10MB